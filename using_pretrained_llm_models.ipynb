{"cells":[{"cell_type":"markdown","metadata":{"id":"0IcWqdkJye1Q"},"source":["# Using Pretrained LLM Models\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KPXVtGdyax1"},"outputs":[],"source":["# Installing the bitsandbytes library\n","!pip install -q -U bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5co_ONxqzmqW"},"outputs":[],"source":["# Installing the transformers library\n","!pip install -q -U git+https://github.com/huggingface/transformers.git"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1710350091747,"user":{"displayName":"Talha","userId":"10262663941274356657"},"user_tz":0},"id":"Mo5fLOQJzuDH"},"outputs":[],"source":["# Installing the PEFT library\n","!pip install -q -U git+https://github.com/huggingface/peft.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6deOZ8W8zuFQ"},"outputs":[],"source":["# Installing the accelerate library\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyQT8puQzuHW"},"outputs":[],"source":["# Installing the datasets library\n","!pip install -q datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3GTdVGm4zuJm"},"outputs":[],"source":["# Import AutoTokenizer\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMKGxJ3zzuLz"},"outputs":[],"source":["# Import AutoModelForCausalLM\n","from transformers import AutoModelForCausalLM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAtr3m6zzuNt"},"outputs":[],"source":["# Import BitsAndBytesConfig\n","from transformers import BitsAndBytesConfig"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1m_Yvb0jzuPs"},"outputs":[],"source":["# Selecting a base LLM model for use\n","llm_base_model_to_use = \"\" # Add base LLM to use here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDhnCIwPzuR1"},"outputs":[],"source":["# BitsAndBytes Configurarion\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiXH0wS5zuT0"},"outputs":[],"source":["# AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\n","    llm_base_model_to_use\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teHZl4zizuV2"},"outputs":[],"source":["# Load the model\n","model = AutoModelForCausalLM.from_pretrained(\n","    llm_base_model_to_use,\n","    quantization_config=bnb_config,\n","    device_map={\"\":0}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-uLLNryzuZO"},"outputs":[],"source":["# Text for prediction\n","text_to_complete = \"Hello, how are\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JGuZy8sZ1grP"},"outputs":[],"source":["# Device\n","device = \"cuda:0\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnQA9zRc1lQ9"},"outputs":[],"source":["# Tokenize inputs\n","tokenized_inputs = tokenizer(\n","    text_to_complete,\n","    return_tensors=\"pt\"\n",").to(\n","    device\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XuiAoS741lSu"},"outputs":[],"source":["# Output\n","outputs = model.generate(\n","    **tokenized_inputs,\n","    max_new_tokens=5\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1Z8FofL1lWF"},"outputs":[],"source":["# Print\n","print(\n","    tokenizer.decode(\n","        outputs[0],\n","        skip_special_tokens=True\n","    )\n",")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOA4mlbu1pFB9WQMfvpHhGk","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
