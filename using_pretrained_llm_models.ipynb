{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOA4mlbu1pFB9WQMfvpHhGk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Using Pretrained LLM Models\n"],"metadata":{"id":"0IcWqdkJye1Q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KPXVtGdyax1"},"outputs":[],"source":["# Installing the bitsandbytes library\n","!pip install -q -U bitsandbytes"]},{"cell_type":"code","source":["# Installing the transformers library\n","!pip install -q -U git+https://github.com/huggingface/transformers.git"],"metadata":{"id":"5co_ONxqzmqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Installing the PEFT library\n","!pip install -q -U git+https://github.com/huggingface/peft.git"],"metadata":{"id":"Mo5fLOQJzuDH","executionInfo":{"status":"ok","timestamp":1710350091747,"user_tz":0,"elapsed":5,"user":{"displayName":"Talha","userId":"10262663941274356657"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Installing the accelerate library\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git"],"metadata":{"id":"6deOZ8W8zuFQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Installing the datasets library\n","!pip install -q datasets"],"metadata":{"id":"HyQT8puQzuHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import AutoTokenizer\n","from transformers import AutoTokenizer"],"metadata":{"id":"3GTdVGm4zuJm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import AutoModelForCausalLM\n","from transformers import AutoModelForCausalLM"],"metadata":{"id":"vMKGxJ3zzuLz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import BitsAndBytesConfig\n","from transformers import BitsAndBytesConfig"],"metadata":{"id":"TAtr3m6zzuNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Selecting a base LLM model for use\n","llm_base_model_to_use = \"\" # Add base LLM to use here"],"metadata":{"id":"1m_Yvb0jzuPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BitsAndBytes Configurarion\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")"],"metadata":{"id":"eDhnCIwPzuR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\n","    llm_base_model_to_use\n",")"],"metadata":{"id":"xiXH0wS5zuT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the model\n","model = AutoModelForCausalLM.from_pretrained(\n","    llm_base_model_to_use,\n","    quantization_config=bnb_config,\n","    device_map={\"\":0}\n",")"],"metadata":{"id":"teHZl4zizuV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Text for predict\n","text_to_complete = \"Hello, how are\""],"metadata":{"id":"s-uLLNryzuZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Device\n","device = \"cuda:0\""],"metadata":{"id":"JGuZy8sZ1grP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize inputs\n","tokenized_inputs = tokenizer(\n","    text_to_complete,\n","    return_tensors=\"pt\"\n",").to(\n","    device\n",")"],"metadata":{"id":"TnQA9zRc1lQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Output\n","outputs = model.generate(\n","    **tokenized_inputs,\n","    max_new_tokens=5\n",")"],"metadata":{"id":"XuiAoS741lSu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print\n","print(\n","    tokenizer.decode(\n","        outputs[0],\n","        skip_special_tokens=True\n","    )\n",")"],"metadata":{"id":"W1Z8FofL1lWF"},"execution_count":null,"outputs":[]}]}